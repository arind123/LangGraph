{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "e044c231",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "from langgraph.graph import StateGraph, END, START\n",
    "from langchain_openai import ChatOpenAI\n",
    "from dotenv import load_dotenv\n",
    "import json\n",
    "import os\n",
    "import re\n",
    "from typing import TypedDict, List, Dict, Optional\n",
    "from IPython.display import Image, display\n",
    "import openpyxl\n",
    "import re\n",
    "from openpyxl.utils import get_column_letter, coordinate_to_tuple, column_index_from_string\n",
    "\n",
    "from openpyxl.formula.tokenizer import Tokenizer\n",
    "import ast\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "e9de1927",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def get_dependencies_from_tokens(formula, current_sheet, all_headers_map):\n",
    "    \"\"\"\n",
    "    Uses the official Excel formula tokenizer to find sheet and cell references.\n",
    "    \"\"\"\n",
    "    tok = Tokenizer(formula)\n",
    "    dependencies = []\n",
    "\n",
    "    for token in tok.items:\n",
    "        # We only care about OPERAND tokens (cells, ranges, sheet refs)\n",
    "        if token.type == \"OPERAND\":\n",
    "            value = token.value\n",
    "            sheet_name = current_sheet\n",
    "            \n",
    "            # 1. Check if there is a sheet reference (e.g., Sales!D2)\n",
    "            if \"!\" in value:\n",
    "                sheet_part, cell_part = value.split(\"!\")\n",
    "                sheet_name = sheet_part.strip(\"'\")\n",
    "                value = cell_part\n",
    "            \n",
    "            # 2. Extract column letters from the cell/range (e.g., D2:D10 -> D)\n",
    "            # Find all sequences of letters that look like column IDs\n",
    "            col_matches = re.findall(r'[A-Z]+', value)\n",
    "            \n",
    "            for col_letter in col_matches:\n",
    "                try:\n",
    "                    col_idx = column_index_from_string(col_letter)\n",
    "                    if sheet_name in all_headers_map and col_idx in all_headers_map[sheet_name]:\n",
    "                        header = all_headers_map[sheet_name][col_idx]\n",
    "                        dependencies.append(f\"{sheet_name}.{header}\")\n",
    "                except ValueError:\n",
    "                    continue # Not a valid column letter\n",
    "\n",
    "    return list(set(dependencies))\n",
    "\n",
    "def get_all_sheet_headers(wb):\n",
    "    all_headers = {}\n",
    "    for sheet_name in wb.sheetnames:\n",
    "        ws = wb[sheet_name]\n",
    "        all_headers[sheet_name] = {\n",
    "            c: ws.cell(row=1, column=c).value \n",
    "            for c in range(1, ws.max_column + 1) \n",
    "            if ws.cell(row=1, column=c).value\n",
    "        }\n",
    "    return all_headers\n",
    "\n",
    "def extract_metadata_final(file_path):\n",
    "    wb = openpyxl.load_workbook(file_path, data_only=False)\n",
    "    # Peek at types only\n",
    "    wb_types = openpyxl.load_workbook(file_path, data_only=True)\n",
    "    \n",
    "    all_headers = get_all_sheet_headers(wb)\n",
    "    metadata = {}\n",
    "\n",
    "    for sheet_name in wb.sheetnames:\n",
    "        ws = wb[sheet_name]\n",
    "        ws_types = wb_types[sheet_name]\n",
    "        sheet_formulas = []\n",
    "        \n",
    "        # Track formula headers to filter them out of raw inputs later\n",
    "        formula_header_names = []\n",
    "\n",
    "        for col_idx, header in all_headers[sheet_name].items():\n",
    "            cell = ws.cell(row=2, column=col_idx)\n",
    "            # Get evaluated value to determine data type\n",
    "            type_val = ws_types.cell(row=2, column=col_idx).value\n",
    "            \n",
    "            if cell.data_type == 'f':\n",
    "                formula = cell.value\n",
    "                formula_header_names.append(header)\n",
    "                \n",
    "                deps = get_dependencies_from_tokens(formula, sheet_name, all_headers)\n",
    "                deps = [d for d in deps if d != f\"{sheet_name}.{header}\"]\n",
    "\n",
    "                sheet_formulas.append({\n",
    "                    \"column\": header,\n",
    "                    \"formula\": formula,\n",
    "                    \"dtype\": type(type_val).__name__ if type_val is not None else \"Unknown\",\n",
    "                    \"depends_on\": deps,\n",
    "                    \"method_name\": f\"calculate_{str(header).lower().replace(' ', '_')}\"\n",
    "                })\n",
    "\n",
    "        # --- UPDATED RAW INPUTS LOGIC ---\n",
    "        raw_inputs_with_types = []\n",
    "        for col_idx, header in all_headers[sheet_name].items():\n",
    "            if header not in formula_header_names:\n",
    "                # Get type for raw data columns too\n",
    "                raw_val = ws_types.cell(row=2, column=col_idx).value\n",
    "                raw_inputs_with_types.append({\n",
    "                    \"column\": header,\n",
    "                    \"dtype\": type(raw_val).__name__ if raw_val is not None else \"Unknown\"\n",
    "                })\n",
    "\n",
    "        metadata[sheet_name] = {\n",
    "            \"formulas\": sheet_formulas,\n",
    "            \"raw_inputs\": raw_inputs_with_types\n",
    "        }\n",
    "\n",
    "    return metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "f84c1c12",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class AgentState(TypedDict):\n",
    "    metadata: Dict           # Metadata from your Excel extractor\n",
    "    file_path: str           # Path to the source Excel file\n",
    "    functions: List[str]      # Individual method blocks generated by the Developer\n",
    "    full_code: str           # The final assembled Python script\n",
    "    error_log: Optional[str] # Feedback for the LLM if something fails\n",
    "    iterations: int          # Counter to prevent infinite loops\n",
    "    success: bool            # Final flag for the workflow\n",
    "    \n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-4o\", temperature=0)\n",
    "\n",
    "def function_developer_node(state: AgentState):\n",
    "    all_functions = []\n",
    "    metadata = state[\"metadata\"]\n",
    "    \n",
    "    # System prompt to enforce naming and docstring rules\n",
    "    system_msg = (\n",
    "        \"You are a Python expert. Create a vectorized Pandas function for an Excel formula. \"\n",
    "        \"Each function must include a docstring clearly listing its Excel dependencies. \"\n",
    "        \"Naming convention: use the 'method_name' provided in metadata.\"\n",
    "    )\n",
    "\n",
    "    for sheet_name, content in metadata.items():\n",
    "        for item in content['formulas']:\n",
    "            prompt = f\"\"\"\n",
    "            Sheet: {sheet_name}\n",
    "            Column: {item['column']}\n",
    "            Formula: {item['formula']}\n",
    "            Data Type: {item['dtype']}\n",
    "            Dependencies: {item['depends_on']}\n",
    "            Method Name: {item['method_name']}\n",
    "            \n",
    "            Generate a Python method for a class. Use 'df' as the input. Import required modules within the function. Return ONLY the code inside a markdown code block. No need to be chatty.\n",
    "            Example format:\n",
    "            def calculate_tax(self, df):\n",
    "                '''\n",
    "                Excel Formula: {item['formula']}\n",
    "                Dependencies: {', '.join(item['depends_on'])}\n",
    "                '''\n",
    "                df['{item['column']}'] = ... \n",
    "                return df\n",
    "\n",
    "            \"\"\"\n",
    "            response = llm.invoke([(\"system\", system_msg), (\"human\", prompt)])\n",
    "            code_match = re.search(r\"```python\\s+(.*?)\\s+```\", response.content, re.DOTALL)\n",
    "\n",
    "            if code_match:\n",
    "\n",
    "                code = code_match.group(1)\n",
    "\n",
    "            else:\n",
    "\n",
    "                # Fallback if no backticks\n",
    "\n",
    "                code = response.content\n",
    "            \n",
    "            # print(code)\n",
    "            # print(\"/n\")\n",
    "\n",
    "            all_functions.append(code)\n",
    "                    # print(response)\n",
    "            \n",
    "    return {\"functions\": all_functions}\n",
    "\n",
    "def orchestrator_node(state: AgentState):\n",
    "    \"\"\"\n",
    "    Takes all generated functions and the metadata to write the final, \n",
    "    production-ready Python class.\n",
    "    \"\"\"\n",
    "    metadata = state[\"metadata\"]\n",
    "    functions_list = \"\\n\\n\".join(state[\"functions\"])\n",
    "    \n",
    "    system_msg = (\n",
    "        \"You are a Senior Software Architect. Your job is to assemble a final, \"\n",
    "        \"production-ready Python script. You must output the ENTIRE code block \"\n",
    "        \"including imports, the class definition, all methods, and the orchestrator.\"\n",
    "    )\n",
    "\n",
    "    prompt = f\"\"\"\n",
    "    METADATA:\n",
    "    {metadata}\n",
    "\n",
    "    INDIVIDUAL GENERATED FUNCTIONS:\n",
    "    {functions_list}\n",
    "\n",
    "    TASK:\n",
    "    Write the FINAL and COMPLETE Python script. \n",
    "    \n",
    "    REQUIREMENTS:\n",
    "    1. Include imports: `import pandas as pd` and `import numpy as np`.\n",
    "    2. Define `class ExcelModel:`.\n",
    "    3. Include an `__init__` method if necessary to handle multi-sheet dataframes.\n",
    "    4. Paste all the INDIVIDUAL GENERATED FUNCTIONS provided above inside the class.\n",
    "    5. Write a `transform(self, all_sheets_dict)` method.\n",
    "    6. CRITICAL: Inside `transform`, call the functions in the correct order based on the 'depends_on' metadata.\n",
    "    7. Ensure every function has the docstrings indicating dependencies as previously generated.\n",
    "    8. Output the FULL CODE explicitly. Do not use placeholders like '# ... rest of code'.\n",
    "    \"\"\"\n",
    "\n",
    "    response = llm.invoke([(\"system\", system_msg), (\"human\", prompt)])\n",
    "    \n",
    "    # Clean the code block\n",
    "    code_match = re.search(r\"```python\\s+(.*?)\\s+```\", response.content, re.DOTALL)\n",
    "\n",
    "    if code_match:\n",
    "\n",
    "        code = code_match.group(1)\n",
    "\n",
    "    else:\n",
    "\n",
    "        # Fallback if no backticks\n",
    "\n",
    "        code = response.content\n",
    "    \n",
    "    return {\"full_code\": code, \"success\": True}\n",
    "\n",
    "def syntax_check_node(state: AgentState):\n",
    "    \"\"\"\n",
    "    Validates that the generated full_code is syntactically correct Python.\n",
    "    \"\"\"\n",
    "    code = state[\"full_code\"]\n",
    "    \n",
    "    try:\n",
    "        # 'exec' mode checks the whole block (imports, classes, methods)\n",
    "        ast.parse(code) \n",
    "        print(\"✅ Syntax validation passed.\")\n",
    "        return {\"success\": True, \"error_log\": None}\n",
    "    \n",
    "    except SyntaxError as e:\n",
    "        # Capture the specific line and reason for the LLM to fix\n",
    "        error_details = f\"SyntaxError on line {e.lineno}: {e.msg}\\nContext: {e.text}\"\n",
    "        print(f\"❌ Syntax validation failed: {error_details}\")\n",
    "        return {\n",
    "            \"success\": False, \n",
    "            \"error_log\": f\"The code you generated has a syntax error. Please fix it:\\n{error_details}\",\n",
    "            \"iterations\": state[\"iterations\"] + 1\n",
    "        }\n",
    "    \n",
    "def should_retry(state: AgentState):\n",
    "    if state[\"success\"] or state[\"iterations\"] >= 3:\n",
    "        return END\n",
    "    return \"orchestrator\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "9f725559",
   "metadata": {},
   "outputs": [],
   "source": [
    "builder = StateGraph(AgentState)\n",
    "\n",
    "builder.add_node(\"developer\", function_developer_node)\n",
    "builder.add_node(\"orchestrator\", orchestrator_node)\n",
    "builder.add_node(\"syntax_check\", syntax_check_node)\n",
    "\n",
    "builder.add_edge(START, \"developer\")\n",
    "builder.add_edge(\"developer\", \"orchestrator\")\n",
    "builder.add_edge(\"orchestrator\", \"syntax_check\")\n",
    "builder.add_conditional_edges(\"syntax_check\", should_retry)\n",
    "\n",
    "app = builder.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "26cf6de1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Phase 1: Extracting Metadata from complex_financial_model_4.xlsx ---\n",
      "--- Phase 2: Running LangGraph Agentic Workflow ---\n",
      "✅ Syntax validation passed.\n",
      "------------------------------\n",
      "✅ SUCCESS: Python model saved to: c:\\Users\\arind\\Documents\\GitHub\\LangGraph\\LangGraph\\excel_model_replica.py\n",
      "Total Iterations: 0\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    # 1. Define your file paths\n",
    "    INPUT_EXCEL = \"complex_financial_model_4.xlsx\"\n",
    "    OUTPUT_FILE = \"excel_model_replica.py\"\n",
    "    \n",
    "    # 2. Extract Metadata (using our previous extractor)\n",
    "    print(f\"--- Phase 1: Extracting Metadata from {INPUT_EXCEL} ---\")\n",
    "    metadata_payload = extract_metadata_final(INPUT_EXCEL)\n",
    "    \n",
    "    # 3. Invoke the LangGraph Agent\n",
    "    print(\"--- Phase 2: Running LangGraph Agentic Workflow ---\")\n",
    "    final_state = app.invoke({\n",
    "        \"metadata\": metadata_payload, \n",
    "        \"file_path\": INPUT_EXCEL, \n",
    "        \"iterations\": 0, \n",
    "        \"functions\": [],\n",
    "        \"full_code\": \"\",\n",
    "        \"success\": False,\n",
    "        \"error_log\": None\n",
    "    })\n",
    "    \n",
    "    # 4. Save the Final Code to Disk\n",
    "    if final_state[\"success\"]:\n",
    "        with open(OUTPUT_FILE, \"w\", encoding=\"utf-8\") as f:\n",
    "            f.write(final_state[\"full_code\"])\n",
    "        \n",
    "        print(\"-\" * 30)\n",
    "        print(f\"✅ SUCCESS: Python model saved to: {os.path.abspath(OUTPUT_FILE)}\")\n",
    "        print(f\"Total Iterations: {final_state['iterations']}\")\n",
    "    else:\n",
    "        print(\"-\" * 30)\n",
    "        print(\"❌ FAILURE: The agent could not generate valid code.\")\n",
    "        print(f\"Last Error: {final_state['error_log']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dabe467",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "local-llm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
